{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_task_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/Dataset-Randomizer/blob/master/ner_task_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaS_m0g6AgpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63508bf6-0810-4d6c-9aea-60a8486b34c0"
      },
      "source": [
        "# ML flow to track metrics\n",
        "!pip install mlflow --quiet\n",
        "\n",
        "# Pyngrok to tunnel into a port\n",
        "!pip install pyngrok --quiet\n",
        "\n",
        "# Installing torchtext version 0.8.0\n",
        "!pip install torchtext==0.8.1 --quiet\n",
        "\n",
        "#torchtext.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.2MB 209kB/s \n",
            "\u001b[K     |████████████████████████████████| 378kB 40.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 40.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 26.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 46.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25h  Building wheel for gunicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 747kB 8.4MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU5bOvWGbF-m"
      },
      "source": [
        "### **1) Loading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtlgvgGQ5t-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4f16bec-a97d-4abe-cd21-6c13cda53b20"
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd, numpy as np\n",
        "import torch, torchtext\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt, seaborn as sb\n",
        "\n",
        "# ml flow\n",
        "#import mlflow\n",
        "\n",
        "import random\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torchtext.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5_gL4S1-msD"
      },
      "source": [
        "# Setting random seeds for reproducibility\n",
        "seed = 46\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t68rCeKACH5I"
      },
      "source": [
        "# Function that'll parse the text file and return lists of words & ner tags\n",
        "def text_file_parser(loc: str):\n",
        "\n",
        "  # Creating lists to hold words and ner tag\n",
        "  words, ner_tag = [], []\n",
        "\n",
        "  # Getting the list of all words and tags from the text files\n",
        "  with open(loc) as file:\n",
        "    for line in file:\n",
        "\n",
        "      # Stripping those pesky newline characters\n",
        "      line = line.strip()\n",
        "\n",
        "      if line != '-DOCSTART- -X- -X- O' and line != '':\n",
        "        tokens = line.split(' ')\n",
        "        \n",
        "        # Getting rid of punctuations\n",
        "        if tokens[0].isalpha():\n",
        "          words.append(tokens[0].lower())\n",
        "          ner_tag.append(tokens[3])\n",
        "    \n",
        "  return words, ner_tag \n",
        "\n",
        "# Getting the train & eval dataset\n",
        "train_words, train_ner = text_file_parser('eng_train.txt')\n",
        "\n",
        "eval_words, eval_ner = text_file_parser('eng_testa.txt')\n",
        "\n",
        "test_words, test_ner = text_file_parser('eng_testb.txt')\n",
        "\n",
        "# Setting device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MCnd2eRDGSNo",
        "outputId": "0a959df9-b90c-4a25-f988-6026f25920d5"
      },
      "source": [
        "# Taking a look at the distribution of NER Tags\n",
        "sb.set_style('darkgrid')\n",
        "sb.countplot(train_ner_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b3c354d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0sYy7lyer3Z",
        "outputId": "9d5c6c13-f811-4085-86e7-9d456c4acfed"
      },
      "source": [
        "ner_vocab.freqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B-LOC': 11,\n",
              "         'B-MISC': 31,\n",
              "         'B-ORG': 24,\n",
              "         'I-LOC': 7878,\n",
              "         'I-MISC': 4155,\n",
              "         'I-ORG': 9648,\n",
              "         'I-PER': 10709,\n",
              "         'O': 121695})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZoHV8l62lvB",
        "outputId": "3d213cf3-5211-4d05-eab9-98539146ce7a"
      },
      "source": [
        "# Adjusting class weights to reduce class imbalance.\n",
        "p = ner_vocab.freqs\n",
        "weight = [p[k] for k in p.keys()]\n",
        "total_weight = sum(weight)\n",
        "class_weights = [total_weight/c for c in weight]\n",
        "\n",
        "class_weights = torch.tensor(class_weights, device = device)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5978e+01, 1.2667e+00, 3.7100e+01, 1.4395e+01, 1.9567e+01, 1.4014e+04,\n",
              "        4.9726e+03, 6.4230e+03], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dF3Bl-mbL88"
      },
      "source": [
        "### **2) Torch text for tokenizing and batching data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS57VXyO7PsV"
      },
      "source": [
        "#  -------------- Using torchtext Fields to handle text and tags data processing  -------------\n",
        "from torchtext.data import Example, Field, BucketIterator, Dataset\n",
        "\n",
        "# Creating Fields to handle text data and tags. Setting unk_token = False for tag field.\n",
        "text = Field(lower = True)\n",
        "tags = Field(unk_token = None, pad_token = None)\n",
        "\n",
        "fields = (('text', text), ('tags', tags))\n",
        "\n",
        "# Creating an Example object of each element in train_words. Appending to a list. Creating a Dataset object.\n",
        "def dataset_creator(text_list, tag_list):\n",
        "  train_list = []\n",
        "\n",
        "  for x, y in zip(text_list, tag_list):\n",
        "    train_list.append(Example.fromlist([x, y], fields = fields))\n",
        "\n",
        "  # Creating a Dataset object out of the examples and fields\n",
        "  train_data = Dataset(examples = train_list, fields = fields)\n",
        "\n",
        "  return train_data\n",
        "\n",
        "# Creating Datasets from a list of words and tags\n",
        "train_data = dataset_creator(train_words, train_ner)\n",
        "eval_data = dataset_creator(eval_words, eval_ner)\n",
        "test_data = dataset_creator(test_words, test_ner)\n",
        "\n",
        "# Building vocabulary using build_vocab\n",
        "text.build_vocab(train_data, max_size = vocab_size - 2)\n",
        "tags.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNWmZXcxINba",
        "outputId": "de5bc737-b727-466d-93bd-5a94807ee12b"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(text.vocab)}\")\n",
        "print(f\"Unique tokens in TAG vocabulary: {len(tags.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 15978\n",
            "Unique tokens in TAG vocabulary: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhaSBH3WUDnb",
        "outputId": "048c754c-2edf-4c91-e3b5-f30ef217ac7d"
      },
      "source": [
        "for i in range(5):\n",
        "  print(vars(train_data.examples[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['eu'], 'tags': ['I-ORG']}\n",
            "{'text': ['rejects'], 'tags': ['O']}\n",
            "{'text': ['german'], 'tags': ['I-MISC']}\n",
            "{'text': ['call'], 'tags': ['O']}\n",
            "{'text': ['to'], 'tags': ['O']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkTif6d2Tk5Q",
        "outputId": "299c636b-09f6-44ca-89dc-31e01ab3e97c"
      },
      "source": [
        "print(text.vocab.freqs.most_common(4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 8390), ('of', 3815), ('in', 3621), ('to', 3424)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "648l6gKv-JIo"
      },
      "source": [
        "# Setting batch_size\n",
        "batch_size = 32\n",
        "\n",
        "# Creating a bucket iterator\n",
        "# Defines an iterator that batches examples of similar lengths together.\n",
        "# Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch.\n",
        "\n",
        "train_iterator = BucketIterator(dataset = train_data, batch_size = batch_size, shuffle = True, device = device)\n",
        "\n",
        "eval_iterator = BucketIterator(dataset = eval_data, batch_size = batch_size, shuffle = False, device = device)\n",
        "\n",
        "test_iterator = BucketIterator(dataset = test_data, batch_size = batch_size, shuffle = False, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNPdNzqtbS3R"
      },
      "source": [
        "### **3) Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmB3jMYyfdol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17d66da-7943-429d-b61b-61a89ea6b413"
      },
      "source": [
        "# Model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Ner(nn.Module):\n",
        "\n",
        "    # Defining layer architecture inside the constructor method\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_classes, bidirectional = False):\n",
        "        \n",
        "        # Calling the parent class constructor\n",
        "        super(Ner, self).__init__()\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embed = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embed_dim)\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.lstm = nn.LSTM(input_size = embed_dim, \n",
        "                            hidden_size = hidden_dim, \n",
        "                            num_layers = 1, \n",
        "                            bidirectional = bidirectional,\n",
        "                            bias = False)\n",
        "\n",
        "        # output_shape = num_directions * hidden_size\n",
        "        # Fully-connected layer for classification\n",
        "        self.fc = nn.Linear(in_features = hidden_dim * 2 if bidirectional else hidden_dim, out_features = output_classes)\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, word):\n",
        "      x = self.embed(word)\n",
        "      x, states = self.lstm(x)\n",
        "      x = x[:, -1]\n",
        "      x = self.fc(x)\n",
        "      x = F.log_softmax(x, dim = 1)\n",
        "\n",
        "      return x\n",
        "\n",
        "# Setting up some parameters\n",
        "vocab_size = len(text.vocab)\n",
        "embed_dim = 24\n",
        "output_classes = len(set(train_ner_tags))  \n",
        "hidden_dim = 12\n",
        "bidirectional = True\n",
        "\n",
        "lr = 0.001 #0.001\n",
        "\n",
        "# Epochs \n",
        "epochs = 10\n",
        "\n",
        "\n",
        "# Instantiating the model\n",
        "model = Ner(vocab_size = vocab_size, \n",
        "            embed_dim = embed_dim,\n",
        "            hidden_dim = hidden_dim,\n",
        "            output_classes = output_classes,\n",
        "            bidirectional = bidirectional)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(model.parameters())\n",
        "\n",
        "# Criterion\n",
        "criterion = nn.NLLLoss(weight = class_weights)\n",
        "#criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
        "\n",
        "\n",
        "# Track these parameters also\n",
        "class Params(object):\n",
        "    def __init__(self, batch_size, epochs, lr, hidden_dim, bidirectional, seed, cuda, embed_dim, vocab_size, criterion):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "        self.seed = seed\n",
        "        self.cuda = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.criterion = criterion\n",
        " \n",
        "\n",
        "args = Params(batch_size = batch_size, epochs = epochs, lr = lr, hidden_dim = hidden_dim, bidirectional = bidirectional,\n",
        "              seed = seed, cuda = True, embed_dim = embed_dim, vocab_size = vocab_size,\n",
        "              criterion = criterion)\n",
        " \n",
        "# Model Summary\n",
        "model"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ner(\n",
              "  (embed): Embedding(15978, 24)\n",
              "  (lstm): LSTM(24, 12, bias=False, bidirectional=True)\n",
              "  (fc): Linear(in_features=24, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UHdJBWQbXE4"
      },
      "source": [
        "### **4) Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc_lauKAUYTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f602b47-87c8-4f90-b777-5d37ad4f8b39"
      },
      "source": [
        "# Sklearn metrics\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import mlflow\n",
        "\n",
        "# Training loop\n",
        "\n",
        "# Putting model in train mode\n",
        "model.train()\n",
        "\n",
        "# Metrics dict\n",
        "metrics = {}\n",
        "\n",
        "print('------------  Training  --------------')\n",
        "\n",
        "# Setting an ML flow experiment\n",
        "mlflow.set_experiment(\"NER CoNLL task\")\n",
        "\n",
        "# Stopping any active runs\n",
        "if mlflow.active_run(): mlflow.end_run()\n",
        "\n",
        "# Training + starting an active ml flow run\n",
        "mlflow.start_run(run_name = \"Train/Evaluation/Test metrics of NER classifier\")\n",
        "\n",
        "# Log parameters in mlflow\n",
        "for key, value in vars(args).items():\n",
        "    mlflow.log_param(key, value)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # Calculating training accuracy & loss for every epoch\n",
        "  total_acc, total_count, train_loss = 0, 0, 0.0\n",
        "\n",
        "  # Collecting predictions and true labels for each epoch\n",
        "  preds, true_labels = [], []\n",
        "\n",
        "  # Training batches\n",
        "  for batch in train_iterator:\n",
        "    \n",
        "    # Extract sequences & tags\n",
        "    sequences, tags = batch.text, batch.tags\n",
        "\n",
        "    # Sequences is stored as list of list, so only extracting the 1-D list and reshaping shape from 1-D to 2-D\n",
        "    sequences = sequences[0].reshape(-1, 1)\n",
        "    tags = tags[0]\n",
        "\n",
        "    # Clear out gradients from previous training batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass; feed inputs to model & get outputs\n",
        "    outputs = model(sequences)\n",
        "  \n",
        "    # Calculate loss between model's predictions & actual target\n",
        "    # print(outputs.size(), '\\n\\n', tags.size())\n",
        "    loss = criterion(outputs, tags)\n",
        "\n",
        "    # Back propagate loss throughout the neural network\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on the current gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    # Converting the softmax scores to labels\n",
        "    predicted_label = outputs.argmax(1)\n",
        "    \n",
        "    preds.append(predicted_label.detach().cpu().numpy())\n",
        "    true_labels.append(tags.to('cpu').numpy())\n",
        "\n",
        "    # Calculating accuracy & loss\n",
        "    total_acc += (predicted_label == tags).sum().item()\n",
        "    total_count += tags.size(0)\n",
        "\n",
        "    train_loss += loss.item()\n",
        "  \n",
        "  # Unraveling lists\n",
        "  preds = [pred for array in preds for pred in array]\n",
        "  true_labels = [target for array in true_labels for target in array]\n",
        "\n",
        "  # Precision, Recall & Accuracy\n",
        "  train_precision = round(precision_score(preds, true_labels, average = 'macro'), 4)\n",
        "  train_recall = round(recall_score(preds, true_labels, average = 'macro'), 4)\n",
        "  \n",
        "  loss_ = round(train_loss/len(train_iterator), 4)\n",
        "  train_accuracy = round(total_acc/ total_count, 4)\n",
        "  \n",
        "  # Tracking with MLFlow\n",
        "  mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
        "  mlflow.log_metric(\"train_precision\", train_precision)\n",
        "  mlflow.log_metric(\"train_recall\", train_recall)\n",
        "  mlflow.log_metric(\"train_loss\", loss_)\n",
        "  \n",
        "  print('\\nEpoch {}/{}\\n---------'.format(epoch + 1, epochs))\n",
        "  print('Loss: {}     Accuracy: {}      Precision: {}     Recall: {}     '.format(loss_, train_accuracy, train_precision, train_recall))\n",
        "\n",
        "# Saving the metrics\n",
        "metrics['train_run'] = {'Accuracy': train_accuracy, 'Precision': train_precision, 'Recall': train_recall, 'Loss': loss_}\n",
        "\n",
        "#mlflow.end_run()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------  Training  --------------\n",
            "\n",
            "Epoch 1/10\n",
            "---------\n",
            "Loss: 0.7237     Accuracy: 0.7778      Precision: 0.1463     Recall: 0.2176     \n",
            "\n",
            "Epoch 2/10\n",
            "---------\n",
            "Loss: 0.4731     Accuracy: 0.8181      Precision: 0.2752     Recall: 0.4035     \n",
            "\n",
            "Epoch 3/10\n",
            "---------\n",
            "Loss: 0.3661     Accuracy: 0.8482      Precision: 0.4247     Recall: 0.4049     \n",
            "\n",
            "Epoch 4/10\n",
            "---------\n",
            "Loss: 0.3051     Accuracy: 0.8638      Precision: 0.5038     Recall: 0.5207     \n",
            "\n",
            "Epoch 5/10\n",
            "---------\n",
            "Loss: 0.2655     Accuracy: 0.8764      Precision: 0.6088     Recall: 0.567     \n",
            "\n",
            "Epoch 6/10\n",
            "---------\n",
            "Loss: 0.2382     Accuracy: 0.8928      Precision: 0.6454     Recall: 0.576     \n",
            "\n",
            "Epoch 7/10\n",
            "---------\n",
            "Loss: 0.2184     Accuracy: 0.9058      Precision: 0.6952     Recall: 0.6026     \n",
            "\n",
            "Epoch 8/10\n",
            "---------\n",
            "Loss: 0.2033     Accuracy: 0.9161      Precision: 0.7335     Recall: 0.6248     \n",
            "\n",
            "Epoch 9/10\n",
            "---------\n",
            "Loss: 0.1919     Accuracy: 0.9247      Precision: 0.7526     Recall: 0.6423     \n",
            "\n",
            "Epoch 10/10\n",
            "---------\n",
            "Loss: 0.185     Accuracy: 0.93      Precision: 0.7566     Recall: 0.6555     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cs7CtqSbaYq"
      },
      "source": [
        "### **5) Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opeCnYLXln82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283a370f-73b3-47c6-fcc1-ebb90c8d95bf"
      },
      "source": [
        "# Evaluating on evaluation set ~ eng_testa.txt\n",
        "# Putting model in eval mode\n",
        "model.eval()\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Accuracy\n",
        "eval_acc, eval_count, eval_loss = 0, 0, 0.0\n",
        "\n",
        "# Iterating through batches in the test dataloader\n",
        "for batch in eval_iterator:\n",
        "\n",
        "# Extract sequences & tags\n",
        "  sequences, tags = batch.text, batch.tags\n",
        "  #print(sequences, '\\n\\n', tags)\n",
        "  \n",
        "  # Sequences is stored as list of list, so only extracting the 1-D list and reshaping shape from 1-D to 2-D\n",
        "  sequences = sequences[0].reshape(-1, 1)\n",
        "  tag = tags[0]\n",
        "  \n",
        "  #print(sequences, '\\n\\n', tags)\n",
        "  # Feeding inputs to the model\n",
        "  output = model(sequences)\n",
        "\n",
        "  # Calculate loss between model's predictions & actual target\n",
        "  loss = criterion(output, tag)\n",
        "  eval_loss += loss.item()\n",
        "  \n",
        "  # Deatch predictions from the graph and append to list\n",
        "  preds.append(output.argmax(1).detach().cpu().numpy())\n",
        "  targets.append(tag.to('cpu').numpy())\n",
        "\n",
        "  # Identifying the correctly predicted labels\n",
        "  eval_acc += (output.argmax(1) == tag).sum().item()\n",
        "  eval_count += tag.size(0)\n",
        "\n",
        "\n",
        "# Evaluation Accuracy\n",
        "eval_accuracy = round(eval_acc/eval_count, 4)\n",
        "eval_loss = round(eval_loss/len(eval_iterator), 9)\n",
        "\n",
        "# Unraveling lists\n",
        "preds = [pred for array in preds for pred in array]\n",
        "true_labels = [target for array in targets for target in array]\n",
        "\n",
        "# Precision, Recall & Accuracy\n",
        "eval_precision = round(precision_score(preds, true_labels, average = 'macro'), 4)\n",
        "eval_recall = round(recall_score(preds, true_labels, average = 'macro'), 4)\n",
        "\n",
        "print('Evaluation\\n\\nLoss: {}     Precision: {}     Recall: {}      Accuracy: {}'.format(eval_loss, eval_precision, eval_recall, eval_accuracy))\n",
        "\n",
        "# Tracking them metrics\n",
        "mlflow.log_metric(\"eval_accuracy\", eval_accuracy)\n",
        "mlflow.log_metric(\"eval_precision\", eval_precision)\n",
        "mlflow.log_metric(\"eval_recall\", eval_recall)\n",
        "mlflow.log_metric(\"eval_loss\", eval_loss)\n",
        "\n",
        "\n",
        "# Saving the metrics\n",
        "metrics['evaluation_run'] = {'Accuracy': eval_accuracy, 'Precision': eval_precision, 'Recall': eval_recall, 'Loss': eval_loss}"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "\n",
            "Loss: 0.290104464     Precision: 0.4599     Recall: 0.5158      Accuracy: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsVDjFYbdu5"
      },
      "source": [
        "### **6) Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8aXCbndU2lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c4df57-a007-42ea-8c62-955b4e1d2d8f"
      },
      "source": [
        "# Testing on eng_testb file\n",
        "# Putting model in eval mode\n",
        "model.eval()\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Accuracy\n",
        "test_acc, test_count, test_loss = 0, 0, 0.0\n",
        "\n",
        "# Iterating through batches in the test dataloader\n",
        "for batch in test_iterator:\n",
        "  \n",
        "  # Push variables to device\n",
        "  sequence, tag = batch.text, batch.tags\n",
        "  \n",
        "  # Extracting the sequences and tag from list of list\n",
        "  sequences = sequence[0].reshape(-1, 1)\n",
        "  tag = tag[0]\n",
        "\n",
        "  # Feeding inputs to the model\n",
        "  output = model(sequences)\n",
        "\n",
        "  # Calculate loss between model's predictions & actual target\n",
        "  loss = criterion(output, tag)\n",
        "  test_loss += loss.item()\n",
        "\n",
        "  # Deatch predictions from the graph and append to list\n",
        "  preds.append(output.argmax(1).detach().cpu().numpy())\n",
        "  targets.append(tag.to('cpu').numpy())\n",
        "\n",
        "  # Identifying the correctly predicted labels\n",
        "  test_acc += (output.argmax(1) == tag).sum().item()\n",
        "  test_count += tag.size(0)\n",
        "\n",
        "\n",
        "# Test Accuracy & loss\n",
        "test_accuracy = round(test_acc/test_count, 4)\n",
        "test_loss = round(test_loss/len(test_iterator), 4)\n",
        "\n",
        "# Unraveling lists\n",
        "preds = [pred for array in preds for pred in array]\n",
        "true_labels = [target for array in targets for target in array]\n",
        "\n",
        "# Precision, Recall & Accuracy\n",
        "test_precision = round(precision_score(preds, true_labels, average = 'macro'), 4)\n",
        "test_recall = round(recall_score(preds, true_labels, average = 'macro'), 4)\n",
        "\n",
        "print('Testing \\n\\nLoss: {}     Precision: {}     Recall: {}      Accuracy: {}'.format(test_loss, test_precision, test_recall, test_accuracy))\n",
        "\n",
        "# Tracking them metrics\n",
        "mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "mlflow.log_metric(\"test_precision\", test_precision)\n",
        "mlflow.log_metric(\"test_recall\", test_recall)\n",
        "mlflow.log_metric(\"test_loss\", test_loss)\n",
        "\n",
        "# Saving the metrics\n",
        "metrics['test_run'] = {'Accuracy': test_accuracy, 'Precision': test_precision, 'Recall': test_recall, 'Loss': test_loss}\n",
        "\n",
        "mlflow.end_run()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing \n",
            "\n",
            "Loss: 0.4641     Precision: 0.3779     Recall: 0.4844      Accuracy: 0.8598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzX8Fj4-bhd0"
      },
      "source": [
        "### **7) ML flow UI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2IlQyjRW3Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f94dc5-3b9a-4668-fc42-d5dac4b5028c"
      },
      "source": [
        "# Create remote tunnel using ngrok to allow local port access\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the port for mlflow UI \n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "\n",
        "# Terminate open tunnels if they exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting up auth token\n",
        "NGROK_AUTH_TOKEN = \"1qk6KrMTlhKWnSdPGaDLvhiX75k_g7tSEN89evvPDpNEDDk4\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 \n",
        "ngrok_tunnel = ngrok.connect(addr = \"5000\", proto = \"http\", bind_tls = True)\n",
        "\n",
        "print(\"MLflow's UI to view tracked metrics:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow's UI to view tracked metrics: https://7742f5b8a746.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNl70MvGIUP7",
        "outputId": "92097965-b792-4cf4-d402-4a1a63831ec8"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(metrics)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'evaluation_run': {'Accuracy': 0.9007,\n",
            "                    'Loss': 0.290104464,\n",
            "                    'Precision': 0.4599,\n",
            "                    'Recall': 0.5158},\n",
            " 'test_run': {'Accuracy': 0.8598,\n",
            "              'Loss': 0.4641,\n",
            "              'Precision': 0.3779,\n",
            "              'Recall': 0.4844},\n",
            " 'train_run': {'Accuracy': 0.93,\n",
            "               'Loss': 0.185,\n",
            "               'Precision': 0.7566,\n",
            "               'Recall': 0.6555}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}